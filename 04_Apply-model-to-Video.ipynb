{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Actual Use : Violence detection for .mp4 video file\n",
    "* By using MobileNet base model & trained LSTM model, we can detect violent behavior in any video files(.avi, .mp4) and save output file.\n",
    "* **`Before run this file, Please check this`**:\n",
    "    * 01_video-to-numpy-save.ipynb\n",
    "    * 02_create-numpy-datasets_training-test.ipynb\n",
    "    * 03_MobileNet.ipynb\n",
    "    * 04_MobileNet_LSTM_model.ipynb\n",
    "* **`Are those files exist on there?`** Those files were made by 01~04_MobileNet.ipynb files.\n",
    "    * Trained LSTM model : 210512_MobileNet_model_epoch100.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:24:41.707649Z",
     "iopub.status.busy": "2021-05-11T02:24:41.707649Z",
     "iopub.status.idle": "2021-05-11T02:25:05.586551Z",
     "shell.execute_reply": "2021-05-11T02:25:05.586551Z",
     "shell.execute_reply.started": "2021-05-11T02:24:41.707649Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 # openCV 4.5.1\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time \n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize \n",
    "from PIL import Image, ImageFont, ImageDraw # add caption by using custom font\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-A. Load Model Files\n",
    "* **`base_model`** : MobileNet\n",
    "* **`model`** : trained LSTM model file. `210512_MobileNet_model_epoch100.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. base_model : MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:05.587429Z",
     "iopub.status.busy": "2021-05-11T02:25:05.587429Z",
     "iopub.status.idle": "2021-05-11T02:25:06.200785Z",
     "shell.execute_reply": "2021-05-11T02:25:06.200785Z",
     "shell.execute_reply.started": "2021-05-11T02:25:05.587429Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model=keras.applications.mobilenet.MobileNet(input_shape=(160, 160, 3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet', classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model : trained LSTM model(.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:06.201803Z",
     "iopub.status.busy": "2021-05-11T02:25:06.201803Z",
     "iopub.status.idle": "2021-05-11T02:25:08.747439Z",
     "shell.execute_reply": "2021-05-11T02:25:08.746474Z",
     "shell.execute_reply.started": "2021-05-11T02:25:06.201803Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=keras.models.load_model('mobilenet4-4(76).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-B. Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Function : video_reader()\n",
    "* Load video file >> Scaling, Resizing >> Transform to Numpy array >> return Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save2Npy(file_dir, save_dir):\n",
    "    \"\"\"This function loads videos, transforms each of them to a Numpy array, and saves them in the selected folder.\n",
    "    :: file_dir :: This folder has original video files.\n",
    "    :: save_dir :: You'll save transformed Numpy arrays in this folder.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):  # If there is no save_dir folder, then create a new folder there.\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    file_list = os.listdir(file_dir)  # Make a list of video file names in file_dir folder.\n",
    "    \n",
    "    for file in tqdm(file_list):\n",
    "        frames = np.zeros((30, 160, 160, 3), dtype=np.float64)\n",
    "        i = 0\n",
    "        \n",
    "        vid = cv2.VideoCapture(os.path.join(file_dir, file))  # Create cv2.VideoCapture() Object for each video file.\n",
    "        \n",
    "        while i < 30:\n",
    "            grabbed, frame = vid.read()\n",
    "            \n",
    "            if not grabbed:  # If the frame couldn't be read, break the loop\n",
    "                break\n",
    "                \n",
    "            frm = resize(frame, (160, 160, 3))\n",
    "            frm = np.expand_dims(frm, axis=0)\n",
    "            \n",
    "            if np.max(frm) > 1:\n",
    "                frm = frm / 255.0   ##normalization\n",
    "                \n",
    "            frames[i][:] = frm      ##access each frame in frames (columns and rows)\n",
    "            i += 1\n",
    "\n",
    "        vid.release()  # Release the VideoCapture object to free up resources\n",
    "\n",
    "        video_name = file.split('.')[0]\n",
    "        save_path = os.path.join(save_dir, video_name + '.npy')\n",
    "\n",
    "        np.save(save_path, frames)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.748467Z",
     "iopub.status.busy": "2021-05-11T02:25:08.748467Z",
     "iopub.status.idle": "2021-05-11T02:25:08.763424Z",
     "shell.execute_reply": "2021-05-11T02:25:08.762399Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.748467Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def video_reader(cv2, filename):\n",
    "    \"\"\"Load 1 video file. Next, read each frame image and resize as (fps, 160, 160, 3) shape and return frame Numpy array.\"\"\"\n",
    "    \n",
    "    frames=np.zeros((30, 160, 160, 3), dtype=np.float32) #> (fps, img size, img size, RGB)\n",
    "    \n",
    "    i=0\n",
    "    print(frames.shape)\n",
    "    vid=cv2.VideoCapture(filename) # read frame img from video file.\n",
    "    \n",
    "    while i < 30:\n",
    "            grabbed, frame = vid.read()\n",
    "            \n",
    "            if not grabbed:  # If the frame couldn't be read, break the loop\n",
    "                print(\"FAILED\")\n",
    "                break\n",
    "                \n",
    "            frm = resize(frame, (160, 160, 3))\n",
    "            frm = np.expand_dims(frm, axis=0)\n",
    "            \n",
    "            if np.max(frm) > 1:\n",
    "                frm = frm / 255.0   ##normalization\n",
    "                \n",
    "            frames[i][:] = frm      ##access each frame in frames (columns and rows)\n",
    "            i += 1\n",
    "    \n",
    "    print('Reading Video')\n",
    "    \n",
    "        \n",
    "    return frames\n",
    "\n",
    "# def video_reader(cv2, filename):\n",
    "#     frames = np.zeros((30, 160, 160, 3), dtype=np.float32)  # (fps, img size, img size, RGB)\n",
    "\n",
    "#     i = 0\n",
    "#     print(frames.shape)\n",
    "#     vid = cv2.VideoCapture(filename)  # read frame img from video file.\n",
    "\n",
    "#     while i < 30:\n",
    "#         grabbed, frame = vid.read()\n",
    "        \n",
    "#         if not grabbed:  # If the frame couldn't be read, break the loop\n",
    "#             print(\"FAILED\")\n",
    "#             break\n",
    "            \n",
    "#         frm = cv2.resize(frame, (160, 160))\n",
    "#         frm = np.expand_dims(frm, axis=0)\n",
    "        \n",
    "#         if np.max(frm) > 1:\n",
    "#             frm = frm / 255.0  # normalization\n",
    "            \n",
    "#         frames[i] = frm\n",
    "#         i += 1\n",
    "\n",
    "#     vid.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "#     print('Reading Video')\n",
    "\n",
    "#     return frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function : create_pred_imgarr()\n",
    "* Extract features of each frame img by using base_model(MobileNet)\n",
    "* Reshape features Numpy array to insert LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.764428Z",
     "iopub.status.busy": "2021-05-11T02:25:08.764428Z",
     "iopub.status.idle": "2021-05-11T02:25:08.779354Z",
     "shell.execute_reply": "2021-05-11T02:25:08.778373Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.764428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pred_imgarr(base_model, video_frm_ar):\n",
    "    \"\"\"Insert base_model(MobileNet) and result of video_reader() function.\n",
    "    This function extract features from each frame img by using base_model.\n",
    "    And reshape Numpy array to insert LSTM model : (1, 30, 25600)\"\"\"\n",
    "    video_frm_ar_dim=np.zeros((1, 30, 160, 160, 3), dtype=np.float64)\n",
    "    video_frm_ar_dim[0][:][:]=video_frm_ar #> (1, 30, 160, 160, 3)\n",
    "     \n",
    "    # Extract features from each frame img by using base_model(MobileNet)\n",
    "    pred_imgarr=base_model.predict(video_frm_ar)\n",
    "    # Reshape features array : (1, fps, 25600)\n",
    "    pred_imgarr=pred_imgarr.reshape(1, pred_imgarr.shape[0], 5*5*1024)\n",
    "    \n",
    "    return pred_imgarr #> ex : (1, 30, 25600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function : pred_fight()\n",
    "* Distinguish Violence(Fight) / Non-Violence(NonFight)\n",
    "* Insert reshaped-features-array to trained LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.780350Z",
     "iopub.status.busy": "2021-05-11T02:25:08.780350Z",
     "iopub.status.idle": "2021-05-11T02:25:08.795311Z",
     "shell.execute_reply": "2021-05-11T02:25:08.794314Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.780350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_fight(model, pred_imgarr, acuracy=0.9):\n",
    "    \"\"\"If accuracy>=input value(ex:0.9), return (Violence)'True'. else, return 'False'.\n",
    "    ::model:: trained LSTM model (We already load .h5 file in the above.)\n",
    "    ::pred_imgarr:: (1, 30, 25600) shaped Numpy array. Extracted features.\n",
    "    ::accuracy:: default value is 0.9\"\"\"\n",
    "\n",
    "    pred_test=model.predict(pred_imgarr) #> Violence(Fight) : [0,1]. Non-Violence(NonFight) : [1,0]\n",
    "    \n",
    "    if pred_test[0][1] >= acuracy:\n",
    "        return True, pred_test[0][1] #> True, Probability of Violence\n",
    "    \n",
    "    else:\n",
    "        return False, pred_test[0][1] #> False, Probability of Violence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check above functions doing well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load any video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.796307Z",
     "iopub.status.busy": "2021-05-11T02:25:08.796307Z",
     "iopub.status.idle": "2021-05-11T02:25:08.811273Z",
     "shell.execute_reply": "2021-05-11T02:25:08.810270Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.796307Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_file='D:\\\\graduation project\\\\datasets\\\\RWF-2000 Dataset\\\\4-4data\\\\Fight\\\\OAfV0xPIhZw_0.avi'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Check function's operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.812265Z",
     "iopub.status.busy": "2021-05-11T02:25:08.812265Z",
     "iopub.status.idle": "2021-05-11T02:25:11.219381Z",
     "shell.execute_reply": "2021-05-11T02:25:11.219381Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.812265Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 160, 160, 3)\n",
      "FAILED\n",
      "Reading Video\n"
     ]
    }
   ],
   "source": [
    "video_frm_ar=video_reader(cv2, video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:11.220378Z",
     "iopub.status.busy": "2021-05-11T02:25:11.220378Z",
     "iopub.status.idle": "2021-05-11T02:25:11.885930Z",
     "shell.execute_reply": "2021-05-11T02:25:11.884932Z",
     "shell.execute_reply.started": "2021-05-11T02:25:11.220378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 25600)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_imgarr=create_pred_imgarr(base_model, video_frm_ar)\n",
    "pred_imgarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:11.886929Z",
     "iopub.status.busy": "2021-05-11T02:25:11.886929Z",
     "iopub.status.idle": "2021-05-11T02:25:12.471363Z",
     "shell.execute_reply": "2021-05-11T02:25:12.471363Z",
     "shell.execute_reply.started": "2021-05-11T02:25:11.886929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0.15721554)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=pred_fight(model, pred_imgarr, 0.8)\n",
    "preds #> (Violence True or False, Probability of Violence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-C. Define all-in-one function\n",
    "* It contains `video_reader()`, `create_pred_imgarr()`, `pred_fight()` as all-in-one.\n",
    "* Input : 1 Video file\n",
    "* Output : Violence True or False / Probability of Violence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define detect_violence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:12.472361Z",
     "iopub.status.busy": "2021-05-11T02:25:12.472361Z",
     "iopub.status.idle": "2021-05-11T02:25:12.486323Z",
     "shell.execute_reply": "2021-05-11T02:25:12.486323Z",
     "shell.execute_reply.started": "2021-05-11T02:25:12.472361Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_violence(video):\n",
    "    \"\"\" It contains video_reader(), create_pred_imgarr(), pred_fight() function as all-in-one.\n",
    "    ::video:: video file (.mp4, .avi, ...)\n",
    "    \n",
    "    video_reader() : Read each frame img by using openCV. Resize Numpy array\n",
    "    create_pred_imgarr() : Extract features from frame img array by using base model(MobileNet)\n",
    "    pred_fight() : Decide Violence True or False by using trained LSTM model\"\"\"\n",
    "    \n",
    "    video_frm_ar=video_reader(cv2, video) \n",
    "    pred_imgarr=create_pred_imgarr(base_model, video_frm_ar)\n",
    "    \n",
    "    time1=int(round(time.time()*1000))\n",
    "\n",
    "    f, precent=pred_fight(model, pred_imgarr, acuracy=0.5)\n",
    "    \n",
    "    time2=int(round(time.time()*1000))\n",
    "    \n",
    "    result={'Violence': f, #> True(Violence), False(Non-Violence)\n",
    "            'Violence Estimation': str(precent), # Probability of Violence\n",
    "            'Processing Time' : str(time2-time1)} \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test function: detect_violence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:12.487321Z",
     "iopub.status.busy": "2021-05-11T02:25:12.487321Z",
     "iopub.status.idle": "2021-05-11T02:25:15.067789Z",
     "shell.execute_reply": "2021-05-11T02:25:15.067789Z",
     "shell.execute_reply.started": "2021-05-11T02:25:12.487321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 160, 160, 3)\n",
      "Reading Video\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Violence': False,\n",
       " 'Violence Estimation': '0.16408515',\n",
       " 'Processing Time': '396'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_file='D:\\\\graduation project\\\\datasets\\\\CAM\\\\Cam1\\\\v\\\\76.mp4'\n",
    "detect_violence(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05-D. Add caption & Save output video file\n",
    "* **`Add Captions on video file`**\n",
    "    * Violence True or False\n",
    "    * Probability of violence\n",
    "* **`View & Save output video`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting : Input path & Output path\n",
    "* **`input_path`** : input video file\n",
    "* **`output_path`** : You'll save output video file in output_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:21:59.807766Z",
     "iopub.status.busy": "2021-05-11T04:21:59.807766Z",
     "iopub.status.idle": "2021-05-11T04:21:59.820731Z",
     "shell.execute_reply": "2021-05-11T04:21:59.820731Z",
     "shell.execute_reply.started": "2021-05-11T04:21:59.807766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path='D:\\\\graduation project\\\\datasets\\\\RWF-2000 Dataset\\\\4-4data\\\\Fight\\\\rfthfd_535.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path=f'{input_path}+output.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def getTime():\n",
    "    Cairo = pytz.timezone('Africa/Cairo')  # Timezone for Cairo\n",
    "    timeNow = datetime.now(Cairo)\n",
    "    return timeNow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distinguish Violence True or False & Add caption on Video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:22:00.687564Z",
     "iopub.status.busy": "2021-05-11T04:22:00.686566Z",
     "iopub.status.idle": "2021-05-11T04:23:40.674141Z",
     "shell.execute_reply": "2021-05-11T04:23:40.674141Z",
     "shell.execute_reply.started": "2021-05-11T04:22:00.687564Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps : 30.0\n",
      "preds:[[0.8666639 0.1333361]]\n",
      "Results = [[nan nan]]\n",
      "Maximum Probability : nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dr\\anaconda3\\envs\\aggressive_gpu\\lib\\site-packages\\ipykernel_launcher.py:54: RuntimeWarning: Mean of empty slice.\n",
      "c:\\Users\\dr\\anaconda3\\envs\\aggressive_gpu\\lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[[0.94308406 0.05691599]]\n",
      "Results = [[0.8666639 0.1333361]]\n",
      "Maximum Probability : 0.8666638731956482\n",
      "\n",
      "preds:[[0.03482285 0.96517724]]\n",
      "Results = [[0.90487397 0.09512605]]\n",
      "Maximum Probability : 0.9048739671707153\n",
      "\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.022738+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.162206+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.313576+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.452758+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.635267+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.765863+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:26:59.896586+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.038697+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.120669+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.191489+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.264318+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.339950+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.430381+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.550636+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.673112+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.784566+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:00.950774+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.019252+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.119451+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.222469+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.308236+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.417619+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.487891+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.563718+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.684931+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.806151+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:01.886925+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:02.004155+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:02.104278+02:00\n",
      "VIOLENCE ALERT!! \n",
      "TIME: 2024-04-15 15:27:02.186027+02:00\n",
      "preds:[[0.25449488 0.74550515]]\n",
      "Results = [[0.6148569  0.38514313]]\n",
      "Maximum Probability : 0.6148568987846375\n",
      "\n",
      "preds:[[0.08322241 0.9167776 ]]\n",
      "Results = [[0.5247664 0.4752336]]\n",
      "Maximum Probability : 0.5247663855552673\n",
      "\n",
      "There is no frame. Streaming ends.\n",
      "Video recording ends. Release Memory.\n"
     ]
    }
   ],
   "source": [
    "vid=cv2.VideoCapture(input_path)\n",
    "fps=vid.get(cv2.CAP_PROP_FPS) # recognize frames per secone(fps) of input_path video file.\n",
    "print(f'fps : {fps}') # print fps.\n",
    "\n",
    "writer=None\n",
    "(W, H)=(None, None)\n",
    "i=0 # number of seconds in video = The number of times that how many operated while loop .\n",
    "Q=deque(maxlen=128) \n",
    "\n",
    "video_frm_ar=np.zeros((1, int(fps), 160, 160, 3), dtype=np.float64) #frames\n",
    "frame_counter=0 # frame number in 1 second. 1~30\n",
    "frame_list=[] \n",
    "preds=None\n",
    "maxprob=None\n",
    "\n",
    "#. While loop : Until the end of input video, it read frame, extract features, predict violence True or False.\n",
    "# ----- Reshape & Save frame img as (30, 160, 160, 3) Numpy array  -----\n",
    "while True: \n",
    "    frame_counter+=1\n",
    "    grabbed, frm=vid.read() # read each frame img. grabbed=True, frm=frm img. ex: (240, 320, 3)\n",
    "    \n",
    "    if not grabbed:\n",
    "        print('There is no frame. Streaming ends.')\n",
    "        break\n",
    "\n",
    "    if W is None or H is None: # W: width, H: height of frame img\n",
    "        (H, W)=frm.shape[:2]\n",
    "            \n",
    "    output=frm.copy() # It is necessary for streaming captioned output video, and to save that.\n",
    "    \n",
    "    frame=resize(frm, (160, 160, 3)) #> Resize frame img array to (160, 160, 3)\n",
    "    frame_list.append(frame) # Append each frame img Numpy array : element is (160, 160, 3) Numpy array.\n",
    "        \n",
    "    if frame_counter>=fps: # fps=30 et al\n",
    "        #. ----- we'll predict violence True or False every 30 frame -----\n",
    "        #. ----- Insert (1, 30, 160, 160, 3) Numpy array to LSTM model ---\n",
    "        #. ----- We'll renew predict result caption on output video every 1 second. -----\n",
    "        # 30-element-appended list -> Transform to Numpy array -> Predict -> Initialize list (repeat)\n",
    "        frame_ar=np.array(frame_list, dtype=np.float16) #> (30, 160, 160, 3)\n",
    "        frame_list=[] # Initialize frame list when frame_counter is same or exceed 30, after transforming to Numpy array.\n",
    "            \n",
    "        if(np.max(frame_ar)>1): \n",
    "            frame_ar=frame_ar/255.0 # Scaling RGB value in Numpy array\n",
    "        \n",
    "        pred_imgarr=base_model.predict(frame_ar) #> Extract features from each frame img by using MobileNet. (30, 5, 5, 1024)\n",
    "        pred_imgarr_dim=pred_imgarr.reshape(1, pred_imgarr.shape[0], 5*5*1024)#> (1, 30, 25600)\n",
    "\n",
    "        preds=model.predict(pred_imgarr_dim) #> (True, 0.99) : (Violence True or False, Probability of Violence)\n",
    "        print(f'preds:{preds}')\n",
    "        Q.append(preds)\n",
    "    \n",
    "        # Predict Result : Average of Violence probability in last 5 second\n",
    "        if i<5:\n",
    "            results=np.array(Q)[:i].mean(axis=0)\n",
    "        else:\n",
    "            results=np.array(Q)[(i-5):i].mean(axis=0)\n",
    "        \n",
    "        print(f'Results = {results}') #> ex : (0.6, 0.650)\n",
    "            \n",
    "        maxprob=np.max(results) #> Select Maximum Probability\n",
    "        print(f'Maximum Probability : {maxprob}')\n",
    "        print('')\n",
    "            \n",
    "        rest=1-maxprob # Probability of Non-Violence\n",
    "        diff=maxprob-rest # Difference between Probability of Violence and Non-Violence's\n",
    "        th=100\n",
    "            \n",
    "        if diff>0.60: \n",
    "            th=diff # ?? What is supporting basis?\n",
    "        \n",
    "        frame_counter=0 #> Initialize frame_counter to 0\n",
    "        i+=1 #> 1 second elapsed\n",
    "        \n",
    "        # When frame_counter>=30, Initialize frame_counter to 0, and repeat above while loop.\n",
    "                \n",
    "    # ----- Setting caption option of output video -----\n",
    "    # Renewed caption is added every 30 frames(if fps=30, it means 1 second.)\n",
    "    font1=ImageFont.truetype('D:\\\\graduation project\\\\datasets\\\\A-Dataset-for-Automatic-Violence-Detection-in-Videos\\\\violence-detection-dataset\\\\font\\\\ARLRDBD.TTF', int(0.05*W)) # font option\n",
    "    font2=ImageFont.truetype('D:\\\\graduation project\\\\datasets\\\\A-Dataset-for-Automatic-Violence-Detection-in-Videos\\\\violence-detection-dataset\\\\font\\\\ARLRDBD.TTF', int(0.1*W)) #font option\n",
    "    \n",
    "    if preds is not None and maxprob is not None:\n",
    "        if (preds[0][1])<th : #> if violence probability < th, Violence=False (Normal, Green Caption)\n",
    "            text1_1='Normal'\n",
    "            text1_2='{:.2f}%'.format(100-(maxprob*100))\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text1_1, font=font1, fill=(0, 255, 0, 0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text1_2, font=font2, fill=(0, 255, 0, 0))\n",
    "            output=np.array(img_pil)\n",
    "                \n",
    "        else : #> if violence probability > th, Violence=True (Violence Alert!, Red Caption)\n",
    "            text2_1='Violence Alert!'\n",
    "            text2_2='{:.2f}%'.format(maxprob*100)\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text2_1, font=font1, fill=(0, 0, 255, 0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text2_2, font=font2, fill=(0, 0, 255, 0))\n",
    "            output=np.array(img_pil)\n",
    "            timeMoment = getTime()\n",
    "            print(f\"VIOLENCE ALERT!! \\nTIME: {timeMoment}\")\n",
    "        \n",
    "    # Save captioned video file by using 'writer'\n",
    "    if writer is None:\n",
    "        fourcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer=cv2.VideoWriter(output_path, fourcc, 30, (W, H), True)\n",
    "            \n",
    "    cv2.imshow('This is output', output) # View output in new Window.\n",
    "    writer.write(output) # Save output in output_path\n",
    "        \n",
    "    key=cv2.waitKey(round(1000/fps)) # time gap of frame and next frame\n",
    "    if key==27: # If you press ESC key, While loop will be breaked and output file will be saved.\n",
    "        print('ESC is pressed. Video recording ends.')\n",
    "        break\n",
    "    \n",
    "print('Video recording ends. Release Memory.') # Output file will be saved.\n",
    "writer.release()\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
